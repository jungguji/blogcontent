---
title: 대규모 푸시 알림 시스템의 아키텍처 개선에 관한 연구
date: 2025-11-11 21:47:37
tags:
---

## 1. 도입

대규모 사용자 기반을 가진 애플리케이션에서 푸시 알림 시스템은 사용자 참여를 유도하고 중요한 정보를 전달하는 핵심적인 역할을 수행한다. 그러나 사용자 수가 증가함에 따라, 시스템은 대량의 메시지를 안정적이고 신속하게 처리해야 하는 기술적 과제에 직면하게 된다. 본 글에서는 과거 대규모 푸시 알림 시스템의 성능을 ThreadPool을 이용한 병렬 처리로 개선했던 경험을 복기하고, 당시의 기술적 한계를 현재의 관점에서 재평가하여 이를 극복하기 위한 새로운 아키텍처를 제안하고자 한다. 본 연구의 목표는 메시지 큐(Message Queue)와 아웃박스 패턴(Outbox Pattern)을 기반으로 한 차세대 비동기 처리 모델을 설계하여, 시스템의 처리량(Throughput), 안정성(Stability), 그리고 확장성(Scalability)을 획기적으로 개선하는 방안을 탐구하는 데 있다.

## 2. 기존 시스템의 문제 정의

본 연구의 대상이 되는 기존 시스템은 19만 명의 전체 사용자에게 알림을 발송하는 데 5시간 이상이 소요되는 성능 문제를 내포하고 있었다.

### 2.1. 1차 시스템: 단일 스레드 기반 동기 처리 모델

1차 시스템의 아키텍처는 단일 스레드가 페이징(Paging) 기법으로 사용자 정보를 순차 조회하고, 외부 푸시 서비스 API(e.g., FCM, APNS)를 동기적으로 호출하는 구조이다. 특히, 전체 발송 프로세스가 단일 데이터베이스 트랜잭션 내에서 실행되는 특징을 가진다.

```mermaid
    sequenceDiagram
    participant App as Application
    participant DB as Database
    participant PushAPI as Push Service (FCM/APNS)

    Note over App, DB: @Transactional 시작 (거대 트랜잭션)

    loop 190번 페이지 반복
        App->>DB: 사용자 조회 (페이지 N, size=1000)
        activate DB
        DB-->>App: 1000명 사용자 데이터 반환
        deactivate DB

        loop 1000명 사용자 반복
            App->>PushAPI: User(i) 푸시 발송 요청 (동기 호출)
            activate PushAPI
            Note right of App: API 응답까지<br/>스레드 대기 (Blocking)
            PushAPI-->>App: 발송 완료 응답
            deactivate PushAPI
        end
    end

    Note over App, DB: 모든 발송 완료 후<br/>@Transactional 종료 (Commit)
```

이러한 구조는 다음과 같은 명확한 한계를 내포한다.

- 문제점 1: 직렬 처리와 동기 I/O 병목
각 API 호출마다 발생하는 I/O 대기 시간(Blocking)이 누적되어 전체 프로세스의 극심한 성능 저하를 유발한다.
- 문제점 2: 초장기 트랜잭션 (Long-Lived Transaction)
프로세스가 실행되는 수 시간 동안 데이터베이스 리소스에 장시간 락(Lock)이 설정될 수 있으며, 이는 시스템의 다른 부분에 대한 가용성 문제를 야기할 수 있다.
- 문제점 3: 구조적 취약성
단일 트랜잭션 모델은 프로세스 중간에 발생하는 단 한 번의 예외에도 전체 작업이 롤백(Rollback)되는 결과를 초래하여, 시스템의 안정성과 신뢰도를 저해한다.

### 2.2. 2차 시스템: 스레드 풀 기반 병렬 처리 모델

1차 시스템의 성능 한계를 극복하기 위해, 2차 시스템에서는 두 가지 핵심적인 최적화를 적용하였다. 가장 결정적인 개선은 외부 API의 Bulk 처리 방식 도입으로, 이는 네트워크 호출 횟수를 99% 이상 감소시켜 I/O 대기 시간을 획기적으로 줄였다. 이에 더하여, 스레드 풀(Thread Pool)을 이용한 병렬 처리 모델을 적용하여 최적화된 작업을 동시에 수행하도록 하였다.

#### 아키텍처:
1. (Bulk API 적용) 기존의 단일 사용자 호출 방식에서, 100명 단위로 푸시를 일괄 발송할 수 있는 Bulk API를 호출하는 방식으로 로직을 변경한다.
2. (병렬 처리) 시스템의 CPU 코어 수에 맞춰 스레드 풀을 생성하고, 메인 스레드가 조회한 사용자 청크(Chunk)를 각 작업 스레드에 할당하여 Bulk API 호출을 병렬로 실행한다.

```mermaid
graph TD
    subgraph "메인 스레드 (Dispatcher)"
        A(Transaction 시작) --> B{페이지 루프 190번 반복};
        B --> C[DB에서 사용자 1000명 조회 Chunk];
        C --> D{ThreadPool에 작업 제출};
        D --> B;
        B -- 모든 페이지 처리 후 --> E(모든 스레드 작업 완료 대기);
        E --> F(Transaction 종료);
    end

    subgraph "ThreadPool (N개 스레드 병렬 처리)"
        T1(Worker Thread 1)
        T2(Worker Thread 2)
        T3(Worker Thread ... N)

        subgraph "각 Worker Thread의 작업 로직"
            W_START(Chunk 수신) --> W_LOOP{Bulk API 루프 10번 반복};
            W_LOOP --> W_CALL[100명 단위로 Bulk API 동기 호출];
            W_CALL --> W_LOOP;
            W_LOOP -- 완료 --> W_END(작업 종료);
        end

        T1 --> W_START;
        T2 --> W_START;
        T3 --> W_START;
    end

    D -- Chunk 1 --> T1;
    D -- Chunk 2 --> T2;
    D -- Chunk 3... --> T3;
```

이러한 병렬 처리 모델 도입을 통해, 시스템의 총 발송 시간은 5시간에서 30분으로 유의미하게 단축되었다.


#### 한계점:
성능 개선에도 불구하고, 2차 시스템은 여전히 1차 시스템과 동일한 근본적인 한계를 공유한다.

 - 문제점 1: 초장기 트랜잭션 및 DB 병목 지속
전체 발송 프로세스는 여전히 단일 트랜잭션 내에서 실행된다. 다수의 스레드가 동시에 데이터베이스의 공유 리소스에 접근하면서 경합이 발생하고, 이는 전체 처리량을 저하시키는 병목 현상을 유발하며, 초장기 트랜잭션 문제 또한 해결되지 않았다.
 - 문제점 2: 제한적인 확장성 (Vertical Scaling)
 성능은 단일 서버의 CPU 코어 수와 스레드 풀의 크기에 직접적으로 의존한다. 처리량을 높이기 위해서는 서버의 사양을 높여야 하는 수직적 확장(Vertical Scaling)만 가능하며, 여러 서버로 부하를 분산하는 수평적 확장(Horizontal Scaling)이 어려운 구조이다.
 - 문제점 3: 여전한 강한 결합도
 애플리케이션이 푸시 발송이라는 무거운 작업을 직접 수행하는 구조는 변하지 않았다. 이는 시스템의 복잡도를 높이고, 외부 API의 응답 지연이 스레드 풀 전체의 성능에 영향을 미치는 등 여전히 강한 결합도(Tight Coupling) 문제를 내포한다.

## 3. 제안하는 아키텍처: 비동기 메시지 기반 분산 처리 모델

기존 시스템의 한계를 극복하기 위해, 본 연구에서는 각 컴포넌트의 역할을 명확히 분리하고 시스템 간의 결합도를 낮추는 비동기 메시지 기반의 새로운 아키텍처를 제안한다.

### 3.1. 트랜잭션 분리를 위한 아웃박스 패턴 (Outbox Pattern)

푸시 발송 요청의 생성과 실제 발송 행위를 분리하기 위해 [아웃박스 패턴](https://microservices.io/patterns/data/transactional-outbox.html)을 도입한다. 발송 요청이 발생하면, 외부 API를 직접 호출하는 대신 `push_outbox` 테이블에 메시지 데이터를 삽입하는 것으로 로컬 트랜잭션을 완료한다. 이를 통해 외부 시스템의 가용성에 관계없이 핵심 비즈니스 로직의 트랜잭션을 보장하고, 시스템의 응답성을 향상시킨다.

### 3.2. 메시지 큐를 이용한 작업 분산 및 버퍼링

데이터베이스를 작업 큐로 사용하는 방식에서 탈피하여, Kafka 또는 RabbitMQ와 같은 메시지 큐 시스템을 도입한다. 별도의 CDC(Change Data Capture) 프로세서 또는 스케줄러가 `push_outbox` 테이블의 변경 사항을 감지하여 메시지 큐에 작업을 발행(Publish)한다.

- 플랫폼별 Topic 분리: FCM, APNS 등 플랫폼의 이질성을 고려하여, 각 플랫폼에 해당하는 별도의 Topic으로 메시지를 발행한다. (push-fcm-topic, push-apns-topic) 이는 특정 플랫폼의 장애가 다른 플랫폼으로 전파되는 것을 방지하고, 독립적인 확장을 가능하게 한다.

### 3.3. 수평 확장이 가능한 소비자 그룹 (Consumer Group)

각 Topic의 메시지는 독립된 소비자(Consumer) 그룹에 의해 처리된다. 소비자 인스턴스의 수를 조절하는 것만으로 전체 시스템의 처리량을 탄력적으로 조절할 수 있어, 수평적 확장성(Horizontal Scalability)을 확보한다.

### 3.4. 트래픽 분산을 통한 안정성 확보

대규모 푸시 발송으로 인한 동시 접속 부하를 제어하기 위해, 사용자 그룹핑 전략을 적용한다. user_id를 해싱(e.g., user_id % N)하여 사용자를 N개의 그룹으로 균등하게 분배하고, 그룹별로 시차를 두어 푸시를 발송함으로써 서버 부하를 완만하게 제어한다.

```mermaid
graph TD
    subgraph "Application Layer"
        WebApp[API/Web Server]
        AppDB[(DB: Push_Job Table)]
    end

    subgraph "Scheduling & Publishing Layer"
        Scheduler[Batch Scheduler <br/> Poller]
        MQ(Message Queue <br/> Kafka / RabbitMQ)
        
        subgraph "Topic Partitioning"
            FCM_Topic[Topic: FCM]
            APNS_Topic[Topic: APNS]
        end
    end

    subgraph "Consumer Layer (Scale-out)"
        FCM_Consumers[FCM Worker Group]
        APNS_Consumers[APNS Worker Group]
    end
    
    subgraph "External Push Services"
        FCM_Service[FCM Service]
        APNS_Service[APNS Service]
    end

    %% Data Flow
    WebApp -- "1. Register Schedule" --> AppDB
    Scheduler -- "2. Poll Ready Jobs <br/> (Scheduled Time &lt;= Now)" --> AppDB
    
    Scheduler -- "3. Publish Messages" --> MQ
    
    %% Chained link separated for better compatibility
    MQ --> FCM_Topic
    MQ --> APNS_Topic

    FCM_Topic --> FCM_Consumers
    APNS_Topic --> APNS_Consumers

    FCM_Consumers -- "4. Send Bulk Request" --> FCM_Service
    APNS_Consumers -- "4. Send Bulk Request" --> APNS_Service

    %% Style
    style WebApp fill:#f9f,stroke:#333,stroke-width:2px
    style AppDB fill:#f9f,stroke:#333,stroke-width:2px
    style Scheduler fill:#ccf,stroke:#333,stroke-width:2px
    style MQ fill:#ccf,stroke:#333,stroke-width:2px
    style FCM_Consumers fill:#cfc,stroke:#333,stroke-width:2px
    style APNS_Consumers fill:#cfc,stroke:#333,stroke-width:2px
```


## 4. 시스템의 견고성(Robustness) 확보 방안

외부 시스템 연동 시 발생 가능한 실패 상황에 대응하기 위한 전략은 다음과 같다.

    지수 백오프 기반 재시도 (Exponential Backoff Retry): 일시적인 오류(e.g., 5xx HTTP Status)에 대해, 재시도 간격을 점진적으로 늘려가는 지수 백오프 알고리즘을 적용하여 시스템의 불필요한 부하를 방지한다.

    데드 레터 큐 (Dead Letter Queue, DLQ): 지정된 횟수 이상 재시도에 실패한 메시지는 별도의 DLQ로 격리하여, 실패 원인 분석 및 후속 조치를 위한 데이터를 확보한다.

## 5. 결론 및 논의

본 글에서 제안한 메시지 큐 기반의 비동기 아키텍처는 기존 시스템의 DB I/O 병목 문제를 해결하고, 각 컴포넌트의 독립적인 확장을 가능하게 하여 대규모 트래픽에 효과적으로 대응할 수 있는 기반을 마련한다. 또한, 실패 처리 메커니즘을 통해 시스템의 안정성과 데이터 무결성을 보장한다.

물론, 제안된 아키텍처는 메시지 큐 도입에 따른 운영 복잡성 증가 및 최종 일관성(Eventual Consistency) 모델에 대한 이해가 필요하다는 트레이드오프가 존재한다. 그럼에도 불구하고, 비즈니스의 성장에 따라 유연하게 확장할 수 있는 기술적 토대를 마련한다는 점에서 그 효용성은 매우 높다고 판단된다. 향후 연구로는 각 플랫폼별 최적의 Bulk 처리 단위 및 소비자 인스턴스 개수를 산출하기 위한 성능 벤치마크 테스트가 필요하다.